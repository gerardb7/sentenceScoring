{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 1 GPU(s) available.\n",
      "We will use the GPU: GeForce GTX 1660 Ti\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# If there's a GPU available...\n",
    "if torch.cuda.is_available():    \n",
    "\n",
    "    # Tell PyTorch to use the GPU.    \n",
    "    device = torch.device(\"cuda\")\n",
    "\n",
    "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
    "\n",
    "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
    "\n",
    "# If not...\n",
    "else:\n",
    "    print('No GPU available, using the CPU instead.')\n",
    "    device = torch.device(\"cpu\")\n",
    "\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "model = torch.load('/home/gerard/ownCloud/varis_tesi/GlossBERT_datasets/SemCor_full.pt')\n",
    "model.cuda()\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading BERT tokenizer...\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertTokenizer\n",
    "\n",
    "if 'tokenizer' not in globals():\n",
    "  print('Loading BERT tokenizer...')\n",
    "  tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)\n",
    "\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of test sentences: 58,021\n",
      "\n",
      "Preparting BERT test input...\n",
      "...10000 in 5.197318077087402\n",
      "...20000 in 10.00934386253357\n",
      "...30000 in 15.268535137176514\n",
      "...40000 in 20.358628034591675\n",
      "...50000 in 26.19759964942932\n",
      "Elapsed time:  30.13491439819336\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import time\n",
    "import itertools\n",
    "from torch.utils.data import TensorDataset\n",
    "from torch.utils.data import DataLoader, SequentialSampler\n",
    "\n",
    "# Load the dataset into a pandas dataframe.\n",
    "dataset_test = pd.read_csv('GlossBERT_datasets/Evaluation_Datasets/ALL/ALL_test_sent_cls.csv', delimiter='\\t', header=0)\n",
    "\n",
    "# Report the number of sentences.\n",
    "print('Number of test sentences: {:,}\\n'.format(dataset_test.shape[0]))\n",
    "\n",
    "# Create sentence and label lists\n",
    "sentences_test = dataset_test.sentence.values\n",
    "glosses_test = dataset_test.gloss.values.tolist()\n",
    "labels_test = dataset_test.label.values\n",
    "\n",
    "print('Preparting BERT test input...')\n",
    "\n",
    "#if 'encoded_dict' not in globals():\n",
    "input_ids_test = []\n",
    "attention_masks_test = []\n",
    "\n",
    "start_time = time.time()\n",
    "counter = 0\n",
    "\n",
    "for (sent, gloss) in itertools.islice(zip(sentences_test, glosses_test), len(sentences_test)):\n",
    "    # `encode_plus` will:\n",
    "    #   (1) Tokenize the sentence.\n",
    "    #   (2) Prepend the `[CLS]` token to the start.\n",
    "    #   (3) Append the `[SEP]` token to the end.\n",
    "    #   (4) Map tokens to their IDs.\n",
    "    #   (5) Pad or truncate the sentence to `max_length`\n",
    "    #   (6) Create attention masks for [PAD] tokens.\n",
    "    encoded_dict = tokenizer.encode_plus(\n",
    "                      sent,       # sentences are tokenized, so split by whitespace\n",
    "                      gloss,               # glosses require tokenization\n",
    "                      add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
    "                      padding = 'max_length', truncation = True, max_length = 100, # Pad & truncate all sentences.\n",
    "                      return_attention_mask = True,   # Construct attn. masks.\n",
    "                      return_tensors = 'pt'     # Return pytorch tensors.\n",
    "                 )\n",
    "        \n",
    "    # Add the encoded sentence to the list.    \n",
    "    input_ids_test.append(encoded_dict['input_ids'])\n",
    "    \n",
    "    # And its attention mask (simply differentiates padding from non-padding).\n",
    "    attention_masks_test.append(encoded_dict['attention_mask'])\n",
    "    \n",
    "    counter += 1\n",
    "    if counter % 10000 == 0:\n",
    "        print(f'...{counter} in {time.time() - start_time}')\n",
    "\n",
    "print(\"Elapsed time: \", time.time() - start_time)\n",
    "\n",
    "# Convert the lists into tensors.\n",
    "input_ids_test = torch.cat(input_ids_test, dim=0)\n",
    "attention_masks_test = torch.cat(attention_masks_test, dim=0)\n",
    "labels_test = torch.tensor(labels_test)\n",
    "\n",
    "# Set the batch size.  \n",
    "batch_size = 16  \n",
    "\n",
    "# Create the DataLoader.\n",
    "prediction_data = TensorDataset(input_ids_test, attention_masks_test, labels_test)\n",
    "prediction_sampler = SequentialSampler(prediction_data)\n",
    "prediction_dataloader = DataLoader(prediction_data, sampler=prediction_sampler, batch_size=batch_size)\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['The art of change-ringing is peculiar to the English , and , like most English peculiarities , unintelligible to the rest of the world .']\n",
      "['the creation of beautiful or significant things']\n",
      "tensor([0])\n",
      "tensor([  101,  1996,  2396,  1997,  2689,  1011, 13060,  2003, 14099,  2000,\n",
      "         1996,  2394,  1010,  1998,  1010,  2066,  2087,  2394, 14099,  6447,\n",
      "         1010,  4895, 18447, 13348, 18507,  2000,  1996,  2717,  1997,  1996,\n",
      "         2088,  1012,   102,  1996,  4325,  1997,  3376,  2030,  3278,  2477,\n",
      "          102,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0])\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0])\n"
     ]
    }
   ],
   "source": [
    "print(sentences_test[0:1])\n",
    "print(glosses_test[0:1])\n",
    "print(labels_test[0:1])\n",
    "print(input_ids_test[0])\n",
    "print(attention_masks_test[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting labels for 58,021 test sentences...\n",
      "    DONE.\n"
     ]
    }
   ],
   "source": [
    "# Prediction on test set\n",
    "\n",
    "print('Predicting labels for {:,} test sentences...'.format(len(input_ids_test)))\n",
    "\n",
    "# Put model in evaluation mode\n",
    "model.eval()\n",
    "\n",
    "# Tracking variables \n",
    "predictions , true_labels = [], []\n",
    "\n",
    "start_time = time.time()\n",
    "counter = 0\n",
    "\n",
    "# Predict \n",
    "for batch in prediction_dataloader:\n",
    "    # Add batch to GPU\n",
    "    batch = tuple(t.to(device) for t in batch)\n",
    "  \n",
    "    # Unpack the inputs from our dataloader\n",
    "    b_input_ids, b_input_mask, b_labels = batch\n",
    "  \n",
    "    # Telling the model not to compute or store gradients, saving memory and \n",
    "    # speeding up prediction\n",
    "    with torch.no_grad():\n",
    "        # Forward pass, calculate logit predictions\n",
    "        outputs = model(b_input_ids, token_type_ids=None, \n",
    "                      attention_mask=b_input_mask, labels=None)\n",
    "\n",
    "    logits = outputs[0]\n",
    "\n",
    "    # Move logits and labels to CPU\n",
    "    logits = logits.detach().cpu().numpy()\n",
    "    label_ids = b_labels.to('cpu').numpy()\n",
    "  \n",
    "    # Store predictions and true labels\n",
    "    predictions.append(logits)\n",
    "    true_labels.append(label_ids)\n",
    "  \n",
    "    counter += 1\n",
    "    if counter % 10000 == 0:\n",
    "        print(f'...{counter} in {time.time() - start_time}')\n",
    "\n",
    "print('    DONE.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive samples: 7611 of 58021 (13.12%)\n"
     ]
    }
   ],
   "source": [
    "print('Positive samples: %d of %d (%.2f%%)' % (dataset_test.label.sum(), len(dataset_test.label), (dataset_test.label.sum() / len(dataset_test.label) * 100.0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating Matthews Corr. Coef. for each batch...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gerard/.conda/envs/sbert/lib/python3.8/site-packages/sklearn/metrics/_classification.py:846: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  mcc = cov_ytyp / np.sqrt(cov_ytyt * cov_ypyp)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    DONE.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import matthews_corrcoef\n",
    "\n",
    "matthews_set = []\n",
    "\n",
    "# Evaluate each test batch using Matthew's correlation coefficient\n",
    "print('Calculating Matthews Corr. Coef. for each batch...')\n",
    "\n",
    "# For each input batch...\n",
    "for i in range(len(true_labels)):\n",
    "  \n",
    "    # The predictions for this batch are a 2-column ndarray (one column for \"0\" \n",
    "    # and one column for \"1\"). Pick the label with the highest value and turn this\n",
    "    # in to a list of 0s and 1s.\n",
    "    pred_labels_i = np.argmax(predictions[i], axis=1).flatten()\n",
    "  \n",
    "    # Calculate and store the coef for this batch.  \n",
    "    matthews = matthews_corrcoef(true_labels[i], pred_labels_i)\n",
    "    matthews_set.append(matthews)\n",
    "\n",
    "print('    DONE.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['characteristic of one only; distinctive or special', 'unique or specific to a person or thing or category', 'beyond or deviating from the usual or expected', 'markedly different from the usual']\n",
      "[1 1 0 0]\n",
      "[[ 1.951223   -1.6415026 ]\n",
      " [ 1.2465233  -0.6646069 ]\n",
      " [ 1.0632874  -0.44000393]\n",
      " [ 2.1456618  -1.8866969 ]]\n",
      "[0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "print(glosses_test[5:9])\n",
    "print(true_labels[0][5:9])\n",
    "print(predictions[0][5:9])\n",
    "print(np.argmax(predictions[0], axis=1)[5:9])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    DONE.\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "\n",
    "# Create a barplot showing the MCC score for each batch of test samples.\n",
    "ax = sns.barplot(x=list(range(len(matthews_set))), y=matthews_set, ci=None)\n",
    "\n",
    "plt.title('MCC Score per Batch')\n",
    "plt.ylabel('MCC Score (-1 to +1)')\n",
    "plt.xlabel('Batch #')\n",
    "\n",
    "plt.show()\n",
    "print('    DONE.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total MCC: 0.606\n",
      "Total F1: 0.650\n",
      "Total P: 0.713\n",
      "Total R: 0.598\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import matthews_corrcoef, f1_score, precision_score, recall_score\n",
    "\n",
    "# Combine the results across all batches. \n",
    "flat_predictions = np.concatenate(predictions, axis=0)\n",
    "\n",
    "# For each sample, pick the label (0 or 1) with the higher score.\n",
    "flat_predictions = np.argmax(flat_predictions, axis=1).flatten()\n",
    "\n",
    "# Combine the correct labels for each batch into a single list.\n",
    "flat_true_labels = np.concatenate(true_labels, axis=0)\n",
    "\n",
    "# Calculate the MCC\n",
    "mcc = matthews_corrcoef(flat_true_labels, flat_predictions)\n",
    "\n",
    "f1 = f1_score(flat_true_labels, flat_predictions)\n",
    "precision = precision_score(flat_true_labels, flat_predictions)\n",
    "recall = recall_score(flat_true_labels, flat_predictions)\n",
    "    \n",
    "print('Total MCC: %.3f' % mcc)\n",
    "print('Total F1: %.3f' % f1)\n",
    "print('Total P: %.3f' % precision)\n",
    "print('Total R: %.3f' % recall)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 0 0 1 0 0 0 0 0]\n",
      "[0 0 1 0 1 1 1 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "print(flat_predictions[0:10])\n",
    "print(flat_true_labels[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sbert",
   "language": "python",
   "name": "sbert"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
